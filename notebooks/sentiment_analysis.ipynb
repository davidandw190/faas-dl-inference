{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNsA+1Qs2rtI/39UYSemRnB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidandw190/faas-dl-inference/blob/main/notebooks/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5RHKehwSDi1",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%pip install datasets transformers onnx onnxruntime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the purpuse of this prototype, a small distilled BERT model from Microsoft will be used as our pre-trained model which we fine-tune on the emotion classification task.\n",
        "\n",
        "- See https://huggingface.co/microsoft/xtremedistil-l6-h256-uncased for details.\n"
      ],
      "metadata": {
        "id": "v3qkbnX9S_pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = 'microsoft/xtremedistil-l6-h256-uncased'\n",
        "dataset = load_dataset(\"emotion\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        ""
      ],
      "metadata": {
        "collapsed": true,
        "id": "FPbUFxW_TfWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_train_dataset = tokenized_datasets[\"train\"]\n",
        "full_eval_dataset = tokenized_datasets[\"test\"]"
      ],
      "metadata": {
        "id": "KURN1zSjTopk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kutw4GoUC1U",
        "outputId": "af0e9070-4765-4cfc-d2f0-8492d8b8faf0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6)\n",
        "model = model.to(device)\n",
        ""
      ],
      "metadata": {
        "collapsed": true,
        "id": "GrlTuyVJUHNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DaCU3KSeUX9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "\n",
        "training_args = TrainingArguments(\"test_trainer\",\n",
        "                                  per_device_train_batch_size=128,\n",
        "                                  num_train_epochs=24,learning_rate=3e-05,\n",
        "                                  evaluation_strategy=\"epoch\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=full_train_dataset,\n",
        "    eval_dataset=full_eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "a0mdmEktUcvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "id": "Uo3rkuL8U-ED",
        "outputId": "ed046a03-d01e-4f21-ddbd-e9e3cd9d998b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3000/3000 12:49, Epoch 24/24]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.192076</td>\n",
              "      <td>0.613500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.928103</td>\n",
              "      <td>0.712500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.774844</td>\n",
              "      <td>0.743500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.061000</td>\n",
              "      <td>0.684443</td>\n",
              "      <td>0.764000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.061000</td>\n",
              "      <td>0.616006</td>\n",
              "      <td>0.810500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.061000</td>\n",
              "      <td>0.545634</td>\n",
              "      <td>0.849500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.061000</td>\n",
              "      <td>0.505468</td>\n",
              "      <td>0.848500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.584700</td>\n",
              "      <td>0.455692</td>\n",
              "      <td>0.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.584700</td>\n",
              "      <td>0.419475</td>\n",
              "      <td>0.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.584700</td>\n",
              "      <td>0.395776</td>\n",
              "      <td>0.885000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.584700</td>\n",
              "      <td>0.366400</td>\n",
              "      <td>0.891500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.404500</td>\n",
              "      <td>0.347821</td>\n",
              "      <td>0.890500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.404500</td>\n",
              "      <td>0.332479</td>\n",
              "      <td>0.895500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.404500</td>\n",
              "      <td>0.321336</td>\n",
              "      <td>0.898000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.404500</td>\n",
              "      <td>0.303322</td>\n",
              "      <td>0.907500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.308500</td>\n",
              "      <td>0.287879</td>\n",
              "      <td>0.907500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.308500</td>\n",
              "      <td>0.279545</td>\n",
              "      <td>0.916500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.308500</td>\n",
              "      <td>0.269702</td>\n",
              "      <td>0.921000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.308500</td>\n",
              "      <td>0.263918</td>\n",
              "      <td>0.919000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.248900</td>\n",
              "      <td>0.260422</td>\n",
              "      <td>0.919500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.248900</td>\n",
              "      <td>0.255381</td>\n",
              "      <td>0.919500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.248900</td>\n",
              "      <td>0.250307</td>\n",
              "      <td>0.925000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.248900</td>\n",
              "      <td>0.249648</td>\n",
              "      <td>0.925500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.219000</td>\n",
              "      <td>0.249252</td>\n",
              "      <td>0.924000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3000, training_loss=0.47109615834554036, metrics={'train_runtime': 770.0358, 'train_samples_per_second': 498.678, 'train_steps_per_second': 3.896, 'total_flos': 1423136673497088.0, 'train_loss': 0.47109615834554036, 'epoch': 24.0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "IqH4Zr5oVByI",
        "outputId": "33b7d593-7429-47b6-bf59-df0f82caac0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.24925249814987183,\n",
              " 'eval_accuracy': 0.924,\n",
              " 'eval_runtime': 2.4446,\n",
              " 'eval_samples_per_second': 818.114,\n",
              " 'eval_steps_per_second': 102.264,\n",
              " 'epoch': 24.0}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exporting the PyTorch model to ONNX format for serving with ONNX Runtime Web"
      ],
      "metadata": {
        "id": "xLITYL95Zeon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import transformers.convert_graph_to_onnx as onnx_convert\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "3Fpu3c0yZmaT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = transformers.pipeline(\"text-classification\",model=model,tokenizer=tokenizer)\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "onnx_convert.convert_pytorch(pipeline, opset=14, output=Path(\"classifier.onnx\"), use_external_format=False)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hwWEjo7tZ4Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install onnx onnxruntime"
      ],
      "metadata": {
        "collapsed": true,
        "id": "F2IdoXIdbIc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "\n",
        "quantize_dynamic(\"classifier.onnx\", \"classifier_int8.onnx\",\n",
        "                 weight_type=QuantType.QUInt8)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VZB9z4c6bMOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the accuracy using ONNX-Runtime inference - validating PyTorch inference versus ONNX-Runtime"
      ],
      "metadata": {
        "id": "lmKopInmZ2gT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "aaJnqgmBccpD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = ort.InferenceSession(\"classifier.onnx\")\n",
        "session_int8 = ort.InferenceSession(\"classifier_int8.onnx\")\n",
        "\n",
        "input_feed = {\n",
        "    \"input_ids\": np.array(full_eval_dataset['input_ids']),\n",
        "    \"attention_mask\": np.array(full_eval_dataset['attention_mask']),\n",
        "    \"token_type_ids\": np.array(full_eval_dataset['token_type_ids'])\n",
        "}"
      ],
      "metadata": {
        "id": "zqQgwUX-HzKI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = session.run(input_feed=input_feed,output_names=['output_0'])[0]\n",
        "out_int8 = session_int8.run(input_feed=input_feed,output_names=['output_0'])[0]\n",
        "\n",
        "predictions = np.argmax(out, axis=-1)\n",
        "predictions_int8 = np.argmax(out_int8, axis=-1)"
      ],
      "metadata": {
        "id": "fe7eMnhNH30C"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=predictions, references=full_eval_dataset['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "994ROYZvH7me",
        "outputId": "f35e9f7c-7780-49cb-ff6d-cfbfa64c6103"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.924}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=predictions_int8, references=full_eval_dataset['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKAY9IOUICNr",
        "outputId": "52ccc6da-6d07-4ea1-e89c-7c12a0319790"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.849}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('classifier_int8.onnx')\n",
        "files.download('classifier.onnx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PX1zK4KvIILY",
        "outputId": "bab94117-501d-486b-f5a2-cb839ecf3a24"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e5704a1c-b840-4ae7-8b6e-bb6847124098\", \"classifier_int8.onnx\", 13081963)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e56b0e60-ea73-442c-93cb-9b65a41607be\", \"classifier.onnx\", 51163253)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}